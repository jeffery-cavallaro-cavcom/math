\documentclass[letterpaper,12pt,fleqn]{article}
\usepackage{matharticle}
\pagestyle{empty}
\DeclareMathOperator{\spn}{span}
\DeclareMathOperator{\range}{range}
\newcommand{\vu}{\vec{u}}
\newcommand{\vv}{\vec{v}}
\newcommand{\vw}{\vec{w}}
\newcommand{\vz}{\vec{0}}
\newcommand{\F}{\mathbb{F}}
\begin{document}
\section*{Vector Spaces}

\begin{definition}[Vector Space]
  A \emph{vector space} $V(V,+,\cdot,\F)$ is a set of objects $V$ called
  $\emph{vectors}$ and a field $\F$ of \emph{scalars} with the well-defined operations of
  \emph{vector addition} and \emph{scalar multiplication} such that the following ten
  axioms hold:
  $\forall,\vu,\vv\in V$ and $\forall\,a,b\in\F$:
  \begin{enumerate}
  \item $\vu+\vv\in V$
  \item $\vu+\vv=\vv+\vu$
  \item $(\vu+\vv)+\vw=\vu+(\vv+\vw)$
  \item $\exists\,\vz\in V,\vu+\vz=\vu$
  \item $\exists\,(-\vu)\in V,\vu+(-\vu)=\vz$
  \item $a\vu\in V$
  \item $1\vu=\vu$
  \item $a(\vu+\vv)=a\vu+a\vv$
  \item $(a+b)\vu=a\vu+b\vu$
  \item $(ab)\vu=a(b\vu)$
  \end{enumerate}
\end{definition}

\begin{example}
  The set $\F^n$ of column vectors form a vector space under the operations of
  component-wise addition and scalar multiplication:
  \[\F^n=\left\{\begin{bmatrix} x_1 \\ \vdots \\ x_n \end{bmatrix}\mid x_k\in\F\right\}\]
\end{example}

\begin{definition}
  The vector space $\{\vz\}$ is called the \emph{zero vector space}.
\end{definition}

Note that vector spaces are never empty because they must contain at least the zero
vector.

\newpage

\subsection*{Subspaces}
  
\begin{definition}[Subspace]
  Let $V$ be a vector space and $S\subseteq V$. To say that $S$ is a \emph{subspace} of
  $V$ means that $S$ is also a vector space using the same scalar field and the same
  operations as $V$.

  $\{\vz\}$ and $V$ are called the \emph{trivial} subspaces of $V$. All other subspaces
  of $V$ are called \emph{non-trivial}.

  To say that $S$ is a \emph{proper} subspace of $V$ means $S\ne V$.
\end{definition}

\begin{theorem}[Subspace Test]
  Let $V$ be a vector space. $S\subseteq V$ is a subspace of $V$ iff:
  \begin{enumerate}
  \item $\vz\in S$
  \item $S$ is closed under vector addition.
  \item $S$ is closed under scalar multiplication.
  \end{enumerate}
\end{theorem}

\begin{theorem}
  Let $V$ be a vector space and $\{S_i\mid i\in I\}$ be a family of subspaces of $V$:
  \[S=\bigcap_{i\in I}S_i\]
  is a subspace of $V$.
\end{theorem}

\begin{theorem}
  Let $V$ be a vector space and let $U$ and $W$ be two subspaces of $V$:
  \[U+W=\{\vu+\vw\mid\vu\in U\ \mbox{and}\ \vw\in W\}\]
  is a subspace of $V$.
\end{theorem}

\newpage

\subsection*{Span}

\begin{definition}[Span]
  Let $V$ be a vector space and let $S=\{\vv_1,\ldots,\vv_n\}\subseteq V$. The
  \emph{span} of $S$, denotes $\spn(S)$, is the intersection of all subspaces of $V$
  containing $S$.

  Thus, $\spn(S)$ is itself a subspace of $V$.

  Note that since $\{\vz\}$ is a subset of every subspace of $V$, by definition:
  \[\spn(\{\})=\{\vz\}\]

  To say that $S$ \emph{spans} $V$ means:
  \[\spn(S)=V\]
\end{definition}

\begin{definition}[Linear Combination]
  Let $V$ be a vector space over a field $\F$ and let
  $S=\{\vv_1,\ldots,\vv_n\}\subseteq V$ and $c_1,\ldots,c_n\in\F$:
  \[\sum_{k=1}^nc_k\vv_k\in V\]
  is called a \emph{linear combination} of $S$ in $V$.

  If all $c_k=0$ then the linear combination is called \emph{trivial}; otherwise, it is
  called \emph{non-trivial}.

  Note that linear combinations are always finite sums.
\end{definition}

\begin{theorem}
  Let $V$ be a vector space over a field $\F$ and let
  $S=\{\vv_1,\ldots,\vv_n\}\subseteq V$. The span of $S$ is the set of all possible
  linear combinations of $S$ in $V$:
  \[\spn(S)=\left\{\sum_{k=1}^nc_k\vv_k\mid c_k\in\F\right\}\]
\end{theorem}

\begin{theorem}
  Let $V$ be a vector space and $U$ and $W$ be subspaces of $V$:
  \[U+W=\spn(U\cup V)\]
\end{theorem}

\newpage

\subsection*{Linear Independence}

\begin{definition}[Linear Independence]
  Let $V$ be a vector space over a field $F$ and $S\subseteq V$. To say that $S$ is
  \emph{linearly independent} means for all $\{\vv_1,\ldots,\vv_n\}\subseteq S$:
  \[\sum_{k=0}^nc_k\vv_k=\vz\implies\forall\,c_k=0\]
  In other words, for any subset of vectors from $S$, only the trivial combination
  results in the zero vector.

  Otherwise, $S$ is said to be \emph{linearly dependent}---there exists a non-trivial
  linear combination of the vectors that equals the zero vector.

  By definition, $\{\vz\}$ is linearly dependent; however, $\{\}$ is linearly independent.
\end{definition}

\begin{theorem}
  A set of two vectors is linearly independent iff one is a scalar multiple of the other.
\end{theorem}

\begin{theorem}
  A set of vectors is linearly independent iff one can be written as a linear combination
  of the others.
\end{theorem}

\newpage

\subsection*{Basis}

\begin{definition}
  Let $V$ be a vector space and let $S\subseteq V$. To say that $S$ is a basis for $V$
  means:
  \begin{enumerate}
  \item $\spn(S)=V$
  \item $S$ is linearly independent
  \end{enumerate}
\end{definition}

\begin{theorem}
  Every basis for a particular vector space $V$ has the same cardinality, called the
  dimension of the vector space and denoted $\dim V$.
\end{theorem}

\begin{theorem}
  Let $V$ be a vector space and $S\subseteq V$. $S$ can be either reduced or extended
  (with additional vectors from $V$) to form a basis for $V$.
\end{theorem}

\begin{theorem}
  Let $W$ be a subspace of a vector space $V$:
  \[\dim W\le\dim V\]
\end{theorem}

\begin{theorem}
  Let $U$ and $W$ be subspaces of a vector space $V$:
  \[\dim(U\cap W)=\dim U+\dim W-\dim(U+W)\]
\end{theorem}

\begin{theproof}
  $U\cap W\subseteq U$ and $U\cap W\subseteq W$ \\
  So, $\dim(U\cap W)\le\dim U$ and $\dim(U\cap W)\le\dim W$ \\
  Let $\{\vv_1,\ldots,\vv_k\}$ be a basis for $U\cap W$ \\
  Extend the basis for $U\cap W$ to a basis for
  $U: \{\vv_1,\ldots,\vv_k,\vu_1,\ldots,\vu_j\}$ \\
  Likewise, extend the basis for $U\cap W$ to a basis for
  $W: \{\vv_1,\ldots,\vv_k,\vw_1,\ldots,\vw_p\}$ \\
  Thus, $\dim U=k+j$ and $\dim W=k+p$
  
  Consider the set $S=\{\vv_1,\ldots,\vv_k,\vu_1,\ldots,\vu_k,\vw_1,\ldots,\vw_p\}$

  Assume $\vv\in U+W$ \\
  $\exists\,\vu\in U$ and $\exists\,\vw\in W$ such that $\vv=\vu+\vw$ \\
  So $\exists\,a_i,b_i\in\F,\vu=\sum_{i=1}^ka_i\vv_i+\sum_{i=1}^jb_i\vu_i$ \\
  Likewise, $\exists\,c_i,d_i\in\F,\vw=\sum_{i=1}^kc_i\vv_i+\sum_{i=1}^pd_i\vw_i$ \\
  And so:
  \begin{eqnarray*}
    \vv &=& \vu+\vw \\
    &=& \left(\sum_{i=1}^ka_i\vv_i+\sum_{i=1}^jb_i\vu_i\right)+
    \left(\sum_{i=1}^kc_i\vv_i+\sum_{i=1}^pd_i\vw_i\right) \\
    &=& \sum_{i=1}^k(a_i+c_i)\vv_i+\sum_{i=1}^jb_i\vu_i+\sum_{i=1}^pd_i\vw_i \\
    &\in& \spn(S)
  \end{eqnarray*}

  Now, assume $\vv\in\spn(S)$ \\
  So $\exists\,a_i,b_i,c_i\in\F,\vv=\sum_{i=1}^ka_i\vv_i+\sum_{i=1}^jb_i\vu_i+
  \sum_{i=1}^pd_i\vw_i$ \\
  But $\sum_{i=1}^ka_i\vv_i+\sum_{i=1}^jb_i\vu_i\in U$ and
  $\sum_{i=1}^pd_i\vw_i\in W$ \\
  $\therefore \vv\in U+W$

  $\therefore \spn(S)=U+V$

  Now, assume $\sum_{i=1}^ka_i\vv_i+\sum_{i=1}^jb_i\vu_i+\sum_{i=1}^pc_i\vw_i=\vz$ \\
  $\sum_{i=1}^ka_i\vv_i+\sum_{i=1}^jb_i\vu_i=-\sum_{i=1}^pc_i\vw_i$ \\
  Let $\vv=\sum_{i=1}^ka_i\vv_i+\sum_{i=1}^jb_i\vu_i=-\sum_{i=1}^pc_i\vw_i$ \\
  But $\vv\in U$ and $\vv\in W$, and so $\vv\in U\cap W$ \\
  So, $\exists\,d_i\in\F,\vv=\sum_{i=1}^kd_i\vv_i$ \\
  $\sum_{i=1}^ka_i\vv_i+\sum_{i=1}^jb_i\vu_i=\sum_{i=1}^kd_i\vv_i$ \\
  $\sum_{i=1}^k(a_i-di)\vv_i+\sum_{i=1}^jb_i\vu_i=\vz$ \\
  But $\{\vv_1,\ldots,\vv_k,\vu_1,\ldots,\vu_j\}$ is a basis for $U$ and is thus an
  independent set \\
  $\therefore\forall\,b_i=0$

  We now have $\sum_{i=1}^ka_i\vv_i+\sum_{i=1}^pc_i\vw_i=\vz$ \\
  But $\{\vv_1,\ldots,\vv_k,\vw_1,\ldots,\vw_p\}$ is a basis for $W$ and is thus an
  independent set \\
  $\therefore\forall\,a_i=0$ and $\forall\,c_i=0$

  Thus, $S$ is an independent set that spans $U+W$ and is therefore a basis for $U+W$
  and:
  \[\dim(U+W)=k+j+p\]

  Finally:
  \begin{eqnarray*}
    \dim U+\dim V-\dim(U+V) &=& (k+j)+(k+p)-(k+j+p) \\
    &=& k \\
    &=& \dim(U\cup W)
  \end{eqnarray*}
\end{theproof}

\newpage

\begin{example}
  Let:
  \[U=\spn\left(\left\{\begin{bmatrix}1 \\ 0 \\ 3 \\ 0\end{bmatrix},
  \begin{bmatrix}0 \\ 2 \\ 0 \\ 1\end{bmatrix}\right\}\right)=
    \range\left(\begin{bmatrix}1 & 0 \\ 0 & 2 \\ 3 & 0 \\ 0 & 1\end{bmatrix}\right)\]
  \[W=\spn\left(\left\{\begin{bmatrix}1 \\ 2 \\ 2 \\ 1\end{bmatrix},
  \begin{bmatrix}1 \\ 0 \\ 0 \\ 0\end{bmatrix},
  \begin{bmatrix}0 \\ 1 \\ 1 \\ 0\end{bmatrix}\right\}\right)=
    \range\left(\begin{bmatrix}1 & 1 & 0 \\ 2 & 0 & 1 \\ 2 & 0 & 1 \\ 1 & 0 & 0
    \end{bmatrix}\right)\]

  $\dim U=2$ \\
  $\dim W=3$

  $U+W=\range\left(\begin{bmatrix}1 & 0 & 1 & 1 & 0 \\ 0 & 2 & 2 & 0 & 1 \\
      3 & 0 & 2 & 0 & 1 \\ 0 & 1 & 1 & 0 & 0\end{bmatrix}\right)$

  \begin{eqnarray*}
    \begin{bmatrix}1 & 0 & 1 & 1 & 0 \\ 0 & 2 & 2 & 0 & 1 \\
      3 & 0 & 2 & 0 & 1 \\ 0 & 1 & 1 & 0 & 0\end{bmatrix} &\sim&
    \begin{bmatrix}1 & 0 & 1 & 1 & 0 \\ 0 & 2 & 2 & 0 & 1 \\
      0 & 0 & -1 & -3 & 1 \\ 0 & 1 & 1 & 0 & 0\end{bmatrix} \\
    &\sim& \begin{bmatrix}1 & 0 & 1 & 1 & 0 \\ 0 & 1 & 1 & 0 & 0 \\
      0 & 0 & -1 & -3 & 1 \\ 0 & 2 & 2 & 0 & 1\end{bmatrix} \\
    &\sim& \begin{bmatrix}1 & 0 & 1 & 1 & 0 \\ 0 & 1 & 1 & 0 & 0 \\
      0 & 0 & -1 & -3 & 1 \\ 0 & 0 & 0 & 0 & 1\end{bmatrix} \\
  \end{eqnarray*}

  $\dim(U+W)=4$

  $\dim(U\cap W)=2+3-4=1$
\end{example}

\end{document}
